## 1. 开场：

　　张拔院士是早期就在强调常识获取难题的研究者之一，所以在2019年1月11日，我到清华大学参加了张钹院士所在的一个会议，并在茶歇时间与张院士聊了关于常识获取的难题以及我在he中的做法。

## 2. 篇外

　　朱松纯教授做的是大任务，他早在2005年就回国成立莲花山研究院，然后做数据标注（后来李飞飞的imageNet的根)。后他意识到因果的重要性，回归到符号主义（符号主义的焦点在因果逻辑推理），注重以任务主导的智能研究。但所有的符号主义学派都会面临到最大的一个问题，即张钹院士提到的常识获取问题，这个问题从1958年左右西蒙和纽厄尔的General Problem Solvel，开始就已经像恶梦一样缠绕着整个符号派，包括后来的专家系统，CYC等都在试图解决这一问题。而专家系统等也因这个问题，而无法获得广泛的应用。甚至可以说，是此问题直接导致了第二次人工智能寒冬。

> 另外，值得注意的是，还有jeffhawkins的numenta公司，王培老师的openNars都在尝试解决这一问题，以及昨天会议上唐杰教授所述的认知图谱。

> 其实大家在关注的不是符号主义已取得的成绩，而是制约其更智能的瓶颈。

> 所以几乎每一次只要公开场合张钹院士露面，都会向大家着重强调常识获取（知识源）问题。

## 3. 常识做法总结：

一：人工
1. 人工标注
2. 人工做常识库
3. 人工做知识图谱
4. 人工做事理图谱，语义网络等


二：统计
1. 在人类知识中做统计，比如语料库等


三：预处理
1. 像openNars就是写了一门语言叫narsese，可以人工预处理一些逻辑进去。
2. 像lisp其实也是这种，General Problem Solvel其全名是：前提为问题描述清晰下的通用问题解决器


四：智能体自发动态获取
1. 这种即张钹院士反复强调的常识获取问题，同时也是整个符号派卡了几十年的终极难题
2. 包括numenta、柳州智视、he4o等在探索此条路径，其中he4o有明确的模型方案与代码实现，且已应用在演示程序中。


> 以上四种都有效果。前面的简单，后面的越来越难。但也越来越动态。
其中第四种，是最动态的，对模糊知识的支持也最好，但是最难的，几乎无人能解此题。

## 4. 记录：
　　我昨天在茶歇时间，去找张钹院士进行了短暂的当面交流。

　　我开场即说：“我在业余时间做一个开源内核，其中关于您刚所提到的常识获取问题，我们有一个做法，是从小样本数据中，通过类比，发现规律，并进行抽象的方式，来进行的。在抽象前，数据是模糊的，但抽象后，会变的越来越确切。我称此过程为“定义”，其实就是您所说的常识获取问题，另外这种处理方式在“概念”、“时序”等上面都有应用”。

　　然后我们聊到关于我研究的进展情况，我说我正在我的内核上做朱松纯教授的乌鸦挑战，开发已经完成，正在训练中。在常识获取的问题上，张院士对我的做法是认可的，但并未给出更多建议，因为当时会上场务小姑娘提出让张院士休息片刻，故中断。

　　另外张院士提到我做研究的资金问题，我说我上班赚钱。然后我们很多人都是业余爱好者，大家自发研究，并未有什么额外的资金。

> 定义，是模糊到相对确切的过程。
