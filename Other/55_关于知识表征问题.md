### 《关于知识表征问题》

　　接上文：《不可解释问题》，本文重点描述不可解释问题的解决方法，其实在做知识表示上，有过很多做法，这个百度一查便知。我这里主要提一些关于知识表征中，难题部分。或者说，至今未解决的部分。

　　主谓宾，IfThen，OOP，其实出现过很多表示方式，至今，其实大家最终使用最多的方式，还是图网络，包括知识图谱，整理图谱，语义网络，（前周我参加清华AITime的年会，他们计划中的：“认知图谱”就是属于图网络这类）。这些可能表征特征、概念、推理、价值等。（注：价值的表示上目前应用广泛的应该是权值，但我主张独立的价值网络模块）。关于知识图谱等，最大的坑在于其固化与人工工作量巨大，所以我比较建议使用终身构建的动态网络。

　　两个模型：我这里提两个模型，这两个模型，可以引出两种网络关联关系，一种是组分关系，另一种是抽具象关系。
1. 在eSTST模型中，有讲到信息的组合关系，从最初输入到最终表征的过程。
2. 在吴思教授global&local模型中，有提信息的泛化表示与具象表示间的关系。


两个目前解决的不太好的问题：
1. 抽具象问题。
2. 常识获取问题。

　　第一个，其实有很多做法，比如王培老师的nars中，应该就有is关系。当然也有很多图谱有这种。但我其实比较推荐用类比，然后抽象的方式（扩展阅读候世达老师新作：《表象与本质:类比,思考之源和思维之火》）

　　第二个，常识的获取问题，也是上周我和zb老师面聊了关于常识获取难题的我的做法，并得到zb老师的初步认同。（其实这里最重点是讲知识在未确切时，定义明确之前的模糊状态）。关于常识获取问题，我讲四种方式：

1. **人工标注常识库、图谱等：**

　　最傻而工作量巨大，CYC就做过人工常识库。

2. **统计方式：**

　　很多人可以靠很少代码和工作量，从语料库等中，直接统计出一个图谱，在我们那边群里，就有个朋友，他一个人做了1.4亿的开源知识图谱库。当然还有别的朋友，靠一个人分析语料库，做对话机器人等，此处不详提及。

3. **预处理方式：**

　　其实是真正实现了后天动态，这是质的一步。可以由后天动态的构建网络知识库。比如王培教授的NARS的narsese，或者像lisp，或者General Problem Solver所指的：“前提为问题描述清晰下的通用问题解决器”。

4. **智能体自发动态获取：**

　　是完全免除人工，完全由智能体自身在后天输入的信息中，去一步步找出常识知识等。这种即zb老师常提的常识获取问题，同时也是整个符号派卡了几十年的终极难题，甚至直接导致了第二次人工智能寒冬。

以上四种都有效果，但前面的简单，后面越来越难，但也越来越动态，对模糊知识的支持也越好。
