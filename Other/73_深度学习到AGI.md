## 《深度学习到AGI》
`CreateTime 2021.04.15`

缩写说明：
1. DL指：深度学习
2. AGI指：通用型人工智能

### 1. 简介
　　不好意思俺又批DL，有AGI协会群友在交流中疑惑于DL与AGI到底有什么不同，所以有了本文，同时为了表达对DL的歉意，文中我会指出DL未来可能的改进建议，批评可能有误，建议也可能没价值，见谅。

　　本文重点通过DL的概率决策和HE的递归决策再做对比。

### 2. 我的观点之DL的问题：

@江成_意义片网思想_IT专业大学生 深度学习的关键问题在于:
1. 依赖"同质(标注)"大数据;
2. 模型单一 (不具备通用性,迁移性);
3. 不可解释黑箱;

这些从百度可查,说白了,深度学习为了走通,
1. 走了捷径; (只对首跑出尾0-1的概率数);
2. 也加了作弊器; (同质大数据硬把它顶上去的);

### 3. 我的观点之DL的多模型改进：

@胡晋宁_湖南农大 试想一下,如果DL能够从:
1. **现在做法:**

　　当一场景:itemDemand -> 做大量数据集:bigData -> 训练单一模型:itemModel;

2. **改进建议:**

　　自动根据各种遇到的场景:anyDemand -> 做动态小数据集训练:anyData -> 训练出通用模型:anyModel;

3. **效果对比:**

* DL：无疑itemModel出来的效果是99.999%;

* 而anyModel出来的效果是60%,但是,如果anyModel之间可以互相协作呢?比如:(anyModel1的不置信部分,再跳转到anyModel2解决) 如果跳转一次,效果就会变成:84%,两次就是93.6%

### 4. 我的观点之DL的抽象改进：

1. 那么我们再改进一下,不仅是统计学,而是做一般性抽象;我各举一例:
   - 统计学: 我饿了10次,8次靠吃饭解决,2次靠零食; (80%与20%)
   - 抽象: 我饿了10次,最终靠吃"食物"解决; (100%)

2. 效果说明：
   - 那么再把一般性抽象加入进去,这种多模型间协作又会是怎样呢?
     - 比如:anyModel是abs抽象的,其置信度就是90%;然后它的元素不成立时,依然是做跳转;此时,只要一次跳转就可以达到99%的效果;
   - 当有未吃过的新食物时：如水果。
     - 我们依然可以通过［吃食物］经验来解决之，推断它可以解决饥饿问题。

> 注: 其实并不需要置信度,此处只是为了方便交流理解,而给予的客观信度值;

### 5. 网友提问：

**问题：那么问题来了,如果电脑知道元素成不成立,还要模型来判断干嘛?**

**回答：**
1. 问题就在于,DL不可解释,根本无法给你指出那不成立的10%是什么;
2. 而AGI是可以解释的,我上述提到过,参考第4条效果说明中：“元素不成立时”，即可解释时，哪个元素条件未成立，我们是可判断的，并且可根据其做跳转。

### 6. 总结：

文中重点指出DL的一些关键问题，并且给予了解决方式：使之可解释，模型通用，且不依然同质标注大数据，并且还对迁移性做了支持。

1. 一句话DL势大力沉,但似乎没有AGI想要的那么精巧智美;
2. 搞智能是个精致活,大力打的了铁,但砸不出雕塑艺术品;

### 7.附言:

　　当下深度学习的不可解释问题，有圈内众位大佬们提到。并非我独一份。

　　另外关于深度学习未来方向，当下也正是向着因果在做,而做因果、可解释性、迁移性，与本文提出的方向是类似并不冲突的，所以这一方向并不算我提出的，而是本来人家已经在这么做了。
