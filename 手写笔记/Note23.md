# 九测(融合训练)

> 注:
> 1. 融合训练在八测中已经开始->本章继续;

> 名词解析:
> 1. toFC: 决策流程控制;
> 2. 实概念: 来自inModel中的概念;
> 3. 虚概念: 来自TO解决方案中的概念;
> 4. RFo: 无mv指向的fo;
> 5. IRT: InRethink的简写;

***

<!-- TOC -->

- [九测(融合训练)](#九测融合训练)
  - [n23p01 九测-觅食训练 (getInnerV3回测)](#n23p01-九测-觅食训练-getinnerv3回测)
  - [n23p02 网络可视化迭代](#n23p02-网络可视化迭代)
  - [n23p03 getInnerHN拆分](#n23p03-getinnerhn拆分)
  - [n23p04 加强RFo抽具象关联](#n23p04-加强rfo抽具象关联)
  - [n23p05 九测2-觅食训练 (内中外类比v4 & getInnerV3回测)](#n23p05-九测2-觅食训练-内中外类比v4--getinnerv3回测)
  - [n23p06 反省更理性迭代](#n23p06-反省更理性迭代)
  - [n23p07 九测3-觅食训练 (VRS评价不稳定回测)](#n23p07-九测3-觅食训练-vrs评价不稳定回测)
  - [n23p08 九测4-GL误杀回测 & 变向觅食训练](#n23p08-九测4-gl误杀回测--变向觅食训练)
  - [n23p09 十测-防撞训练&防撞觅食融合训练-子任务测试](#n23p09-十测-防撞训练防撞觅食融合训练-子任务测试)
  - [n23p10 子任务协同迭代v2](#n23p10-子任务协同迭代v2)
  - [n23p11 FRS空S评价迭代-改为自由竞争](#n23p11-frs空s评价迭代-改为自由竞争)
  - [n23p12 十测2-子任务测试](#n23p12-十测2-子任务测试)
  - [n23p13 父子任务防重](#n23p13-父子任务防重)
  - [n23p14 dsFo的全树不应期](#n23p14-dsfo的全树不应期)
  - [n23p15 十测3-子任务测试](#n23p15-十测3-子任务测试)

<!-- /TOC -->

## n23p01 九测-觅食训练 (getInnerV3回测)
`CreateTime 2021.04.11`

在上节中,对理性子任务做了迭代,本节再次对觅食和防撞融合训练,测试之;

| 23011 | 觅食训练最终步骤 (参考22035) |
| --- | --- |
| 1 | `直投,右下飞,直投`, `边直投边飞至右上`x N |
| 2 | `重启,右投,飞至坚果,马上饿`x3 `左投,飞至坚果,马上饿`x3 |
| 3 | `重启,右投,马上饿` (会原地空吃,发现不行再飞至坚果吃) `左投,马上饿`; |

| 23012 | 防撞训练步骤 (参考22161) |
| --- | --- |
| 1 | `直扔木棒`x8向=>习得`F18[A8(无距棒)]->{mv-}` |
| 2 | `偏扔木棒,边右飞边扔`xN=>习得不被撞的经验`Fx->{mv0}` |

| 23013 | getInnerV3()在HN时,传入maskFo为Alg类型错误的BUG `T` |
| --- | --- |
| 调试 | 经调试,错误出现在,当MC转PM进行GL修正失败后,递归回到_Hav找ATHav坚果 |
| 数据 | 此时输出短时结构从父到子为:cFo->cAlg->mAlg->mcValue; |
| 说明 | 即mcValue修正码的父级是实概念(matchAlg),而不是虚概念(curAlg); |
| 分析 | 解决方案的虚概念才需要ATHav,而inModel中的实概念是不需要ATHav的; |
| 治标 | 在传入到getInnerV3的参数做检查,base不是fo类型时,则取base.baseFo; |
| 治本 | toFC中value失败时,如base是replaceAlg跳过,对base.baseAlg做begin; |
| 结果 | 问题本质是`实Alg无需进行ATHav`,治标治本两方案全改掉后ok; |

| 23014 | 无GL距小经验的BUG |
| --- | --- |
| 示图 | ![](assets/439_九测无GL距小经验的BUG.png) |
| 说明 | 在23011第2步中,已经训练右飞变近,但在第3步时,还是未找到GL经验; |
| 调试 | ![](assets/441_23014BUG调试.png) |
|  | 说明:如图TIRFo失败,即当前场景都认识不清,何淡在getInnerV3中应用; |
| TODO | 1. 将TIRFo的结果中,不指向mv的放开 (并处理可能导致的副作用) `T`; |
|  | --> 但仅是放开normal部分,而不放开HNGL和虚mv的部分; |
|  | --> 将不指向mv的命名为matchRFos,原指向的改为matchPFos; |
| TODO | 2. 将TIRFo时,识别目标由matchAFo改为protoAlg (并处理副作用) `T`; |
|  | --> 因为:如图现在matchAFo.A113与inModel.matchAlgs是同层,结构操作乱; |
|  | --> 会导致判断全含时,A113特征不全导致失败; |
|  | --> 并且A113当前向抽象取的assIndexes也不全; |
| TODO | 3. 将TIRFo方法中的assIndexes,改为直接使用inModel.matchAlgs `T`; |
|  | --> 因为TIRAlg不限层,所以无论是matchAlgs或absPorts,都算支持多层; |
|  | --> 结果: 先不改,因为fromRethink时无matchAlgs,但absPorts更通用支持; |

| 23015 | 23014分析2改为protoFo后无法构建F14的问题 `T` |
| --- | --- |
| 简介 | 改为protoFo后,发现最初还没抽象时,仅相似的两个fo无法识别并外类比; |
| 问题 | 无法外类比`A`就无法抽象`B`,无法抽象就无法识别`C`(识别就是识别抽象); |
| 分析 | 以上ABC三模块形成死循环,所以必须在起初留下一个切入口来解决之; |
| 分析 | 改动前无问题,因为matchAFo在构建时没有mAlg就会用partAlg,算切入口; |
| 方案 | 将tirFo的fo参数改为:识别到matchAlg时才用protoFo,否则还用matchAFo; |

| 23016 | 23014分析1放开matchRFos后,应用总结 `T` |
| --- | --- |
| 1 | 原matchFos改为matchPFos后,原调用全不变默认为matchPFos; |
| 2 | 现matchRFos由以下几处调用: |
|  | a. analogyInner_Outside_V3()中联想assFo处改为用matchRFos; |
| TODO | 将有mv指向的fo.ds和无mv指向的fo.ds改为ATPercept和ATReason; |

| 23017 | 回测23014无GL经验BUG `T` |
| --- | --- |
| 日志 | ![](assets/442_回测23014无GL经验BUG.png) |
| 说明 | 如图,当前maskFo仅有protoFo:F203一条,看来并未取到matchFos; |
| 分析 | 1. 在TIRFo识别后,protoFo并非结束,所以并不会与matchFos抽具象关联 |
|  | 2. 现在getInnerV3中取absPorts是取不到matchFos的; |
| 方案 | 直接将protoFo所在的inModel.matchFos传入getInnerV3取GL经验; |
| 延伸 | HN时,没有inModel参数可传,并且似乎与GL时联想路径也不同 `转n23p03`; |
| 结果 | 按着方案,改代码后,依然无法获取GL经验,转23018; |

| 23018 | 取不到GL经验的BUG `转至n23p04` |
| --- | --- |
| 调试 | 调试发现,在内中外类比期就未对matchRFos形成嵌套GL,所以用时取不到; |
| 调试 | 1. 内类比是对protoFo,每次protoFo都不同,无法互相识别为matchRFos; |
|  | 2. 内中外类比是根据matchRFos来联想assFo,从而形成matchRFos的GL; |
|  | 3. 如上死循环,所以protoFo之间的嵌套GL,永远无法互相"内中外类比"; |
|  | 4. 所以matchRFos永远不会指向GL; |
| 分析 | 类似TIR_Fo时使用matchAFo,此处也可以做"激活期"; |
| 方案 | 将相似的protoFo,指向的GL作为assFo与abFo激活类比; |
|  | 注: 因此处partAlg并未做时序识别,故此处相似protoFo由matchRFos向具象取; |
|  | 问题: matchRFos向具象取不到,因为protoFo和matchRFos之间无关联; |
| 结果 | 其本质为matchRFos与protoFo之间无抽具象关联 `转至n23p04`; |

<br><br><br>

## n23p02 网络可视化迭代
`CreateTime 2021.04.11`

说明: 前段时间支持了dsPorts,所以本次将对嵌套迭代;

| 23021 | 嵌套迭代 |
| --- | --- |
| 1 | 将dsPorts支持为嵌套方式展示; |
| 2 | 将hngl支持为嵌套方式展示; |
| UI | ![](assets/440_网络可视化嵌套迭代原型图.png) |
| 说明 | UI:将嵌套支持为点击节点时,在周围展开显示,不同类型采用不同颜色; |

| 23022 | 快捷添加节点迭代 |
| --- | --- |
| 1 | 将addNode窗口的参数,改为指定格式的字符串拼接; |

<br><br><br>

## n23p03 getInnerHN拆分
`CreateTime 2021.04.16`

在getInnerV3迭代后,发现GL和HN的联想是不同路径的(参考23017),本节将针对HN的独立做笔记;

| 23031 | 示例说明:`获取HN经验`的`联想路径` |
| --- | --- |
| 比如 | P-解决方案,想吃桃,步骤如下: |
| 1 | getInnerHN取得: [超市,买得到桃],返给决策; |
| 2 | 又需要找到超市,再到getInnerHN取得:[出发点,去超市],返给决策; |
| 3 | 出发点在inModels中发现自己在家,找到具象时序:[家出发,去,X路A辉超市]; |
| 说明 | 由例可见,二者在联想路径的向性上完全相反; |
|  | 1. GL的路径向性为:下右向上左 (从时序向着抽象的概念的联想); |
|  | 2. HN的路径向性为:左上向右下 (从概念向着时序的具象的联想); |
| 代码 | 独立写getInnerHN方法,并传入cAlg来联想; |


<br><br><br>

## n23p04 加强RFo抽具象关联
`CreateTime 2021.04.21`

1. 在23018中,决策期取不到GL经验的问题,想通过类比期内中外类比解决;
2. 而内中外类比又找不到assFo,因为无"激活期",导致matchRFos的抽象无GL指向;
3. 本质为RFo抽具象太弱,本节重点针对此问题展开,加强RFo的抽具象关联;

| 23041 | 增强RFo抽具象关联-方案1-代码规划 `90%,选用` |
| --- | --- |
| 示图 | ![](assets/443_增强RFo抽具象关联示图.png) |
| TODO1 | **激活期** (初步建立RFo抽具象关联) `T` |
|  | 1. 在TIRFo后,对matchRFos和当前protoFo分别外类比抽象,以增强抽具象; |
| TODO2 | **内中外类比期** (内中外类比v4迭代-改进assFo联想方式) `T` |
|  | 2. 内中外类比先取absFo.assGLFo,将结果absGLFo嵌套在absFo下; |
|  | 3. 再后以absFo向具象取以往protoFo.assGLFo,将结果嵌套在absFo下; |
|  | 注: 关于嵌套在absFo下,参考反向反馈外类比代码 |

| 23042 | 增强RFo抽具象关联-方案2 `5%,不选用` |
| --- | --- |
| 说明 | 直接用protoFo指向matchRFo,然后在absPort中,指定matchIndex; |
| 问题 | 这样虽然看起来网络更简单,但操作复杂度更高; |
| 弃用 | 毕竟现在实现方式并不是并行过滤器,所以此方案在代码操作上麻烦,故弃用; |

<br><br><br>

## n23p05 九测2-觅食训练 (内中外类比v4 & getInnerV3回测)
`CreateTime 2021.04.23`

| 23051 | 获取不到GL问题回测 `不复现` |
| --- | --- |
| 问题 | 测得,PM评价`向→不通过`,明天再重新训练觅食,试下能否复现; |

| 23052 | 右GL正常_左GL无经验的BUG |
| --- | --- |
| 示图 | ![](assets/444_右GL正常_左GL无经验的BUG.png) |

| 23053 | 左果误取右飞GL经验的BUG `T` |
| --- | --- |
| 示图 | ![](assets/445_左果误取右飞GL经验的BUG.png) |
| 分析 | 因为A135和A8是过度抽象的,所以误取很正常,并非BUG; |
| 结果 | 当这些过度抽象之下的所有GL解决方案全被空S评价为否时自然就ok了; |

| 23054 | 左果无GL经验的BUG |
| --- | --- |
| 示图 | ![](assets/446_左果无GL经验的BUG.png) |
| 分析 | 重点查左果在内中外类比v4处,能否给左果嵌套到GL经验; |
| 调试 | 经初步调试,在觅食第2步中,并未内中外类比给`左果`构建GL经验; |
| 疑点 | 1. 时序未去重,导致右果组成同样的时序,有可能有多个; |
|  | > 在ThinkingUtils有过Fo去重方法,后来注掉了,原因忘了; |
|  | > 此问题未必与时序未去重有影响,因为大致只有那一两个同内容重复的时序; |
| 调试 | 按23055训练后,右果有嵌套GL经验,左果仍没有,如下图所示: |
|  | ![](assets/447_左果无GL经验的BUG调试日志.png) |

| 23055 | 觅食训练步骤 |
| --- | --- |
| 1 | `直投,右下飞,直投`, `边直投边飞至右上`x N |
| 2 | `重启,右投很远,飞至坚果` `重启,左投很远,飞至坚果` |
| 3 | `重启,右投,马上饿` `重启,左投,马上饿`; |

| 23056 | 觅食训练步骤调整 |
| --- | --- |
| 1 | `边直投边飞至左下`, `边直投边飞至右上` |
| 2 | `重启,左投,飞至坚果,摸嘴吃`x3 `重启,右投,飞至坚果,摸嘴吃`x3 |
| 3 | `重启,右投,马上饿` `重启,左投,马上饿`; |

| 23057 | 不稳定嵌套GL空S评价未记录为否的BUG `T` |
| --- | --- |
| 示图 | ![](assets/448_不稳定嵌套GL空S评价未记录为否的BUG.png) |
| 说明 | F236的GL是不稳定的,但是左扔,右扔训练多次后,发现空S评价还是全通过; |
| 调试 | 经调试,在analogy_OutRethink中,空S时,构建的时序为nil,导致此BUG; |
| 原因 | 前两天打开fo防重,当content_ps为nil时,会不构建fo,导致空S时序返回空 |
| 方案 | 将fo.create_NoRepeat()改为content_ps为空时,构建新节点,回测ok; |

| 23058 | 右果嵌套GL为0的问题 `T` |
| --- | --- |
| 示图 | ![](assets/449_右果嵌套GL为0的问题.png) |
| 说明 | 训练多次,右果的GL嵌套仍为0条; |
| 分析 | 到内中外类比v4中,调试查`右果`的构建情况,如下: |
| 调试 | absFo很多,但只类比5条,有些absFo压根没类比故没有gl,右果就在此列; |
| 方案 | 调整配置参数,限制每个absFo下assFo数,使每个absFo都有机会类比到gl; |
| 结果 | 修改absFo.con取3条,再取glhnPorts取2条,类比数从5改为20,回测ok; |

| 23059 | 无关稀疏码通不过VRS评价的问题 `转至n23p06` |
| --- | --- |
| 示图 | ![](assets/450_无关稀疏码通不过VRS评价的问题.png) |
| 说明 | 按着23056训练至第3步后,发现PM中,会对`距→`,`Y距`这些评价不通过; |
| 分析 | 最初第三步评价还通过,重复第三步,则可能不通过; |
| 问题 | 所以怀疑是不稳定的VRS评价导致 (易受SP影响) `转至n23p06`; |

<br><br><br>

## n23p06 反省更理性迭代
`CreateTime 2021.04.30`

在23059中,发现VRS易受SP影响,从而使不需要加工的稀疏码在PM中VRS评价不通过,本节将针对此问题,对IO两个反省做理性迭代,使之更明确责任,避免被偶然的S误伤到无辜的稀疏码;

| 23061 | SP导致VRS评价不稳定-解决方案分析 |
| --- | --- |
| 调试 | 经调试,S的主要来源是InRethink; |
| 方案1 | 生成由合适的fromto范围表征的alg来解决,使值域稳定沉淀; |
|  | 扩展思考:from-to可变吗? |
| 方案2 | 更理性反省: 使反省时责任分担更明确,从而避免影响VRS不稳定; |
|  | > Out时,距离没解决时,反省时只有距离做S(100%责任),`向,Y距`等码无责; |
|  | > In时,责任分摊与承担力正相关,如原距离导致90%,那么现也承担90%的责任; |
| 方案3 | 原则: 抽象指导性，评价稳定性。 |
|  | > 先查现抽象构建与评价结果代码,尽量围绕以上两点原则制定方案改动; |

| 23062 | VRS评价的spPorts有重复的问题 `T` |
| --- | --- |
| 示图 | ![](assets/451_VRS评价的spPorts有重复的问题.png) |
| 说明 | 重复评分会影响到VRS评价结果,所以先改了这个后,再看用不用迭代更理性SP; |
| 结果 | 重复的BUG已修复,但回测VRS评价不稳定问题仍然存在; |

| 23063 | SP导致VRS评价不稳定-方案2-取消IRT方案 |
| --- | --- |
| 分析 | InRethink并没有下探到V层次，所以应取消IRT构建SP; |
| 改为 | IRT触发器在取消构建SP后,应改为触发S时吸引注意力,吸引注意力后的操作: |
| 1 | 力度更大的识别,预测到R-任务 (比如动物疯叫预测地震); |
|  | > 力度未必更大,没必要,`所以此条可能不必做任何迭代`; |
| 2 | S则产生纯理性疑问任务 (新任务类型); |
|  | > 疑问任务被解决: 如停车场的某车灯突然灭,其实也没啥不正常; |
|  | > 疑问任务未能解决: 如苹果掉向天上,这事思来考去也不正常; |
|  | > `此条暂不必支持`,等以后需要支持时再来翻看此处; |
| 3 | 关掉IRT `T`; |

| 23064 | SP的再抽象未作用于VRS评价 `T` |
| --- | --- |
| 简介 | 根据23061方案3查代码,发现SP再抽象未作用于VRS评价; |
| 方案 | 将absSP嵌套在protoFo下,以使其作用于VRS评价,以及作用于今后外类比; |
| 示图 | ![](assets/452_SP外类比结果嵌套在protoFo下.png) |
| 结果 | 代码已改动,不过此改动并不能根治VRS评价不稳定问题,需搭配`定责`; |
| 回测 | 发现VRS评价不稳定问题不复现了,因为absSP对VRS影响太强了; |

| 23065 | SP导致VRS评价不稳定-方案2-ORT定责 `修了部分,剩余转至23066` |
| --- | --- |
| 简介 | 在ORT中,定责给gl修正失败的V,而非所有未finish的V; |
| 分析 | 修复23064后,不复现,待再测看能否复现; |
| 结果 | 在修复23064后,发现VRS不稳定的问题无法复现了,所以`定责暂停`不改; |
| 复现 | ![](assets/473_距大于0被VRS评价通过的问题.png) |
| 调试 | 在ORT中,将距>0的P打出来,然后将非距的S也打出来,并从中分析问题; |
|  | ![](assets/474_调试生成距大于0的P的情况.png) |
| TODO | 1. reModel改成最后一个 `T` |
|  | 2. 距20修正ok后改成finish (距>0的P问题修复,因为进入except了) `T` |
|  | 3. S时定责规则改动 `转至23066` |

| 23066 | ORT定责 |
| --- | --- |
| 注 | 未修正部分 = justPValues - 已修正; |
| P定赏 | A:`未修正部分均分赏` 当前做法为A; |
| S定罚 | A:`未修正部分均分责` 或 B:`当前加工失败的那一条全责` 当前做法为A; |
|  | 结果: B改动随后再说,目前不影响训练先不改; |

<br><br><br>

## n23p07 九测3-觅食训练 (VRS评价不稳定回测)
`CreateTime 2021.05.09`

| 23071 | getInner没有不应期导致重复飞错方向的问题 `T` |
| --- | --- |
| 示图 | ![](assets/453_getInner没有不应期导致重复飞错方向的问题.png) |
| 分析 | 当飞错方向时,距离一变,ToValueModel也变了,所以原不应期不再生效; |
|  | 而此时,反省类比还在异步中未执行到,所以空S评价也还没生效; |
| 方案1 | 当ToValueModel变化时,旧ToValueModel的不应期依然有效; |
|  | `5%采用`,因为一米外和千米外可能使用不同的解决方案; |
| 方案2 | 无论是OPushM还是ActYes的触发器,只要其中一个反馈则触发反省; |
|  | `95%采用`,比如车顶前行反后退,我们能立马意识到,不需要等生物钟触发器; |
| 结果 | 根据方案2改掉后,回测问题已解决; |

| 23072 | 飞至坚果飞超了的问题 `不复现` |
| --- | --- |
| 示图 | ![](assets/454_飞至坚果飞超了的问题.png) |
| 说明 | 如图,明明飞到坚果了,却没有吃,飞超了,执行了多次`距6->0`; |
| 分析 | 经调试,在tor_OPushM中,未能对已距0的坚果匹配到反馈,致`6->0`重复; |
| 结果 | 打了调试日志,但不复现,等复现时再看日志分析吧; |

| 23073 | 上果上飞GL经验被空S否掉的问题 `假想2:T` |
| --- | --- |
| 示图 | ![](assets/455_上果上飞GL经验被空S否掉的问题.png) |
| 说明 | 原本已训练好上觅食,但下觅食老失败 |
|  | 多次训练下觅食成功后,发现上觅食GL经验被否 |
| 假想 | 原因: 会不会是因为在4条瞬时长度内,经历了上飞和下飞两个经历; |
|  | 问题: 导致在内类比中,一条空S这么偶然发生了; |
|  | 如假想成立: 那此处关键在于`偶然的一次空S`不应彻底杀掉当前经验; |
|  | 解决方案: 对SP经验,记录sStrong和pStrong,二者自由竞争; |
|  | 结果: 同时发生两个,也不会都是actYes状态,所以此假想不成立; `T` |
| 假想2 | 情况: 距21在飞错方向变成距31后,再飞对方向,飞回21; |
|  | 错误: 在tor_OPushM中,还是和距21在比较,导致21=21反省S; |
|  | 解决方案: 在距31后,即将距21改成actNo状态,避免继续wait等待; |
| 假想3 | 因spFo是防重的,所以在无向果和右果下,会同时嵌套F40[右飞,距近]; |
|  | 当`无向果`的F40否掉后,`右果`下的F40也被否了,转至2307b; |

| 23074 | 变向觅食训练 |
| --- | --- |
| 训练 | 对8个方向都做训练,坚果扔到任何地方都可以自行调整方向飞过去吃掉; |

| 23075 | 变向失败的问题 `T` |
| --- | --- |
| 示图 | ![](assets/456_变向失败的问题.png) |
| 说明 | 已对8个单方向觅食训练ok,但在变向训练中,发现没能变向; |
| 调试 | ![](assets/467_调试变向失败的问题.png) |
| 分析 | ![](assets/468_torOPushM循环衔接To短时记忆示图.png) |
|  | ![](assets/469_torOPushM循环衔接To短时记忆示图.png) |
| 如图 | 当前问题为: 外循环后,衔接尾部还是头部的问题; |
|  | > 原做法为: 从尾部衔接,更新target的独特码,并继续PM; |
|  | > 现需求为: 从头部衔接,将target直接替换掉,并继续决策流程控制; |
| 注: | 其实都是从尾部衔接,只是现需求找更base一层,并交给决策FC来自动分配; |
| 方案 | 在tor_OPushM中不转PM,直接对target.baseAlg再次调用begin决策流程; |
|  | target.base.begin()会自己找到latestProtoA,并继续决策行为化; |

| 23076 | _Hav的不应期太抽象导致常切断决策流程 `T` |
| --- | --- |
| 示图 | ![](assets/470_Hav的不应期太抽象导致常切断决策流程.png) |
| 方案 | 将_Hav()中构建reModel时,把matchA改成protoA; |
| 防错 | 查代码,看所有调用reModel的地方,是否会有别的错误发生; |
| 结果 | 将reModel挂载改成protoA,并将torOPushM调用处改为仅判断pIsM; |

| 23077 | 偶尔距>0通过VRS评价的问题 |
| --- | --- |
| 示图 | ![](assets/471_偶尔距>0通过VRS评价的问题.png) |
| 分析 | 同样是对A8进行评价,为何这么少经验,另外还`不复现`; |

| 23078 | 偶尔很熟的觅食GL找不到经验的问题 `T` |
| --- | --- |
| 示图 | ![](assets/472_偶尔很熟的觅食GL找不到经验的问题.png) |
| 分析 | 经查,用protoFo向抽象联想太不靠谱了,有带mv的fo等等干扰; |
| 调试 | 而tirFo已抽象出absRFo,且内中外类比中将GL嵌套其下,所以: |
| 方案 | 将getInnerGL中的mask参数改为:protoFo+inModel.absRFos后,实测ok; |

| 23079 | 飞错方向再飞回来的protoA会被_GL()不应期掉的问题 `T` |
| --- | --- |
| 示图 | ![](assets/475_GL会不应期掉曾有效的protoA.png) |
| 问题 | 因为alg是防重的,如果飞错方向再飞回来,那么protoAlg会已进入不应期; |
|  | 导致飞回来的protoA不能作为GL加工参考 (如:距20飞错距30再飞回距20); |
| 方案 | 在tor_OPushM中将成功的replaceAlg设置为finish或actNo; |
|  | 然后在_GL()中,仅对actNo的做不应期,finish的不做; |

| 2307a | GL总是优先从protoF取经验但它常常太具象偶然 `T` |
| --- | --- |
| 示图 | ![](assets/476_GL总是优先从protoF取经验但它常常太具象偶然.png) |
| 说明 | 图中显示了protoF的GL经验太具体,指导性弱; |
|  | 另外在变向觅食中因方向多变,上帧经验下帧就不适用了,故其稳定性也差; |
| 分析 | protoF未经先上后下(先指导性后稳定性)的洗礼,必然不确定性大; |
| 结果 | 因protoF的GL不确定性大,改为不从protoF取GL经验 `T`; |

| 2307b | spFo防重导致跨场景误杀 (参考23073) `T方案3已完成` |
| --- | --- |
| 示图 | ![](assets/477_spFo防重导致跨场景误杀.png) |
| 说明 | 如图,F40在无向果下被否,那么在右向果下则被跨界杀; |
| 方案1 | glFo仅对同场景下防重 `5%`; |
|  | 不同场景下的`[拿,来]`显然描述的是相同意思,所以此方案不选择; |
| 方案2 | spFo在构建时,将当前场景标记其中 `20%`; |
|  | 将pointer下加场景标记:baseFoId,在构建fo时,baseFoId做防重判断; |
|  | 分析: 此方案能解决问题,但与方案3效果一样,实现却更复杂; |
| 方案3 | SP仅对同场景下防重 `95%` |
|  | 分析: 本来SP就是嵌套的,而非全局的,所以仅对同场景下防重才是ok的; |
|  | 分析: 可对防重代码,指定防重域valid_ps (比如:当前场景.spPorts); |

<br><br><br>

## n23p08 九测4-GL误杀回测 & 变向觅食训练
`CreateTime 2021.05.23`

| 23081 | SP场景去重后回测还是有误杀情况 `T` |
| --- | --- |
| 示图 | ![](assets/478_SP场景去重后回测还是有误杀情况.png) |
| 说明 | 如上图如示,按照2307b-方案3修改后,还是有误杀情况; |
| 调试 | 觅食训练中,将左右果的SP构建情况打印出来,查原因; |
| 分析 | ![](assets/479_GL误杀问题数据结构图.png) |
| 说明 | 如图如示,GL被跨场景复用了,所以S场景防重无效,GL场景防重才有效; |
| 结果 | 在createFo_NoRepeat()中,对GL类型也支持场景防重; |

| 23082 | 变向觅食训练步骤 |
| --- | --- |
| 1 | `边直投边飞至右上角`,`路径为:↘ → ↗ → ↗ → ↗ → ↗ → ↗` |
| 2 | `右投,右飞至坚果,摸嘴吃`x3 |
| 3 | `重启,右投,马上饿`,(自行飞至食之) |
| 4 | 换个方向,重复3,4步骤; |
| 5 | 变向训练:(坚果投至需要变向,马上饿,自行飞至食之); |
| 结果 | 至此,变向觅食训练成功; |
|  | ![](assets/481_变向飞行成功示图.png) |

| 23083 | 飞至不食BUG `T` |
| --- | --- |
| 示图 | ![](assets/480_飞至不食BUG.png) |
| 结果 | 经查,是因为`inner > delta:-0.2 = energy:0.0`,耗尽活跃度导致; |


<br><br><br>

## n23p09 十测-防撞训练&防撞觅食融合训练-子任务测试
`CreateTime 2021.05.24`

　　在n23p08中，变向觅食训练已经ok，本节将再次进行防撞训练，并且在防撞训练ok后，尝试进行防撞觅食融合训练。

　　在3月底已经写了子任务,但后面因为别的细节问题所阻,一直没测,本节将对子任务进行测试,并修复bug;

| 23091-防撞训练步骤 | 习得 (参考22202) |
| --- | --- |
| 1. `直扔木棒`x8向 | `Same经验: Fx[Ax(无距棒)]->{mv-}` |
| 2. `偏扔木棒`x8向 | `Diff经验: Fx->{mv0}` `P经验` |
| 3. `直扔木棒`x8向 | `S经验` |
| 4. `飞到危险地带,直扔` | R任务决策流程-应预测到危险并躲至安全地方 |

| 23092 | 反思子任务死循环 `T` |
| --- | --- |
| 示图 | ![](assets/482_反思子任务死循环.png) |
| 分析 | 如图,问题在于反思子任务死循环,只要使F4不反思到F20自己即可打破循环; |
| 代码 | 1. 在Fo行为化中,对父级`根任务和子任务`有任何重复的不生成子任务 `T`; |
|  | 2. 在反思评价中,对父级`根任务和子任务`有任务重复的不计入评分 `T`; |
| 结果 | 改代码后,回测ok; |

| 23093 | 防撞Y距VRS评价有误BUG |
| --- | --- |
| 示图 | ![](assets/483_防撞Y距VRS评价有误BUG.png) |
| 说明 | 如图,在第1步训练中,已被撞过数次,但在第3步训练中,Y距评价有误导致不躲; |
| 分析 | P数有为1也有为4,但S数一直是0; |
| 怀疑 | 1. 前段时间将IRT取消掉了,导致SP不够? |
| 调试 | 2. 在第2步训练中,也形成了防撞R任务,只是第2步本来就是偏扔,所以形成P; |
| 方案 | 在训练第1,2步后,再反过来训练第1步,看能否形成S; |
| 结果 | 根据方案对训练步骤进行调整; |

| 23094 | 反思子任务死循环2 `T` |
| --- | --- |
| 示图 | ![](assets/484_反思子任务死循环2.png) |
| 说明 | R子任务时,没把base挂在baseOrGroup下,导致23092收集防重链中断 |
| 结果 | 把R子任务base挂到baseOrGroup下后,防重全了,问题解决; |

| 23095 | 无计可施的R子任务未不应期掉 `T` |
| --- | --- |
| 示图 | ![](assets/485_无计可施的R子任务未不应期掉.png) |
| 方案 | 将决策短时记忆树中,所有failure的R任务加入到不应期,避免重复尝试; |
| 结果 | 将R任务"无计可施"时,设为actNo状态,并在子任务时加入不应期,回测ok; |

| 23096 | 同质子任务 `转至n23p10` |
| --- | --- |
| 说明 | 防撞训练至第4步,下飞,反思预测到多条PFo->{mv-},都生成子任务太繁; |

<br><br><br>

## n23p10 子任务协同迭代v2
`CreateTime 2021.06.05`

　　在23096中,反思多条同质预测都生成了子任务,导致几乎一致的子任务,一次次进行R行为化,白白耗尽思维活跃度,本节将针对此问题,将子任务迭代至v2,对同质子任务之间的协同进行分析解决;

| 23101 | 同质子任务来源说明 `参考23096` |
| --- | --- |
| 示图 | ![](assets/486_一堆同质子任务.png) |
| 说明 | 只是一个小小的飞下动作,反思了一堆非常相似的结果,且都生成了子任务; |

| 23102 | 同质子任务的协同举例分析 |
| --- | --- |
| 举例 | 一只`催饿火神虫`飞过来,多条预测mv如下: |
|  | 预测mv: `1. 有东西害我不爽`,`2.会饿`,`3.会伤`,`4.烧伤`,`5.咬伤`; |
|  | 预测分析: `1最抽象`,`23略抽象`,`45最具象`; |
| 分析 | 1. 抽具象不重要,重要的是共同的ds,所以12345各自形成R子任务不变; |
|  | 2. 当任何一条子任务的解决方案行为化成功时,尝试协同作用于别的任务; |
|  | >> 如子任务2,干掉催饿火神虫后,子任务3自然就ok了; |
|  | >> 关键在于前面子任务的ds经验,同时也是后面别的子任务的ds解决方案; |
| 方案 | 新增子任务不应期: 解决了任何子任务的ds方案的场景fos全加入不应期; |

| 23103 | 子任务协同示图 `T` |
| --- | --- |
| 示图 | ![](assets/487_子任务协同示图.png) |
| 说明 | 如上图,套入23102实例; |
|  | ds1表示解决`会饿`,例如叼一块面包 |
|  | ds2表示解决`有东西害我不爽`,例如干掉`催饿火神虫`; |
|  | 全程为,叼一块面包冲出去干掉催饿火神虫,全部子任务完成; |

<br><br><br>

## n23p11 FRS空S评价迭代-改为自由竞争
`CreateTime 2021.06.05`

　　因为评价的结果不稳定,空S评价为否的一刀切方式显得非常武断,现实世界非常的多变,所以智能体也不可能尽取所有信息,此时网络的首和尾采用竞争,中部保持理性迁移是较好的协作方式;

| 23111 | 以往做法回顾 |
| --- | --- |
| 起点 | 在稀疏码层,HE采用了竞争方式 (束波求和); |
| 中段 | 在中间部分,HE采用了迁移方式,只有100%和0%,没有中间态; |
| 终点 | 在评价部分,HE采用了竞争方式,但不够彻底 `见23112-理感`; |

| 23112 | 终点: 评价竞争回顾 |
| --- | --- |
| 终感 | 其中感性评价: mv部分是自由竞争的; |
|  | > 感感: 价值的迫切度竞争; |
|  | > 感理: 解决方案的强度竞争; |
| 终理 | 但理性评价: 不全; |
|  | > 理感: SP部分,尤其是空S评价,显得非常武断,本节重要改进之; |
|  | > 理理: 对特征,概念,时序三者是否满足只有100%和0%,二值评价; |

| 23113 | FRS空S评价的自由竞争迭代 |
| --- | --- |
| 分析 | 见23112,空S评价中应该带有一些感性的方式,即类似稀疏码VRS自由竞争; |
| TODO | 1. SP仍然改回全局防重 (参考2307b-方案3); |
|  | 2. 对指向SP节点的场景fo.spPort,将sp发生的次数,计为spPort的强度; |
|  | 3. 将空S评价,改为由当前场景的sPort和pPort的强度进行竞争; |
| 疑问 | VRS和FRS都通过SP来实现竞争,但V有值,F却无值; |
| 解答 | 能否通过率来排序? S和P各自有自己的可行率, 然后通过率作为强度; |
| 暂停 | 在变向飞行训练中,此问题也有所体现,但目前主要在做n23p10,`此处暂停`; |

<br><br><br>

## n23p12 十测2-子任务测试
`CreateTime 2021.06.06`

两个多月前,已经写完了子任务ARSTime评价 (见n22p12),现在才真正测到此处,当时写的已经快忘光了,需要先复习下,再测试;

| 23121 | 回顾子任务当时的设计与测试规划 |
| --- | --- |
| 测试1 | 记得子任务的actYes不太一样,回顾下怎么测 `静默actYes测试通过`; |
|  | 体现为`下飞`并不会立马就害怕,如果有吃的,应该能规划先吃,看到木棒再躲; |
| 测试2 | 来的及评价,回顾下代码并测试 `已测ok`; |
| 测试3 | 测试发现Y距的问题,而不是单纯的乱飞; |

| 23122 | 子任务actYes不应期,要照顾到所有subOutModels `T` |
| --- | --- |
| 示图 | ![](assets/488_子任务协作迭代.png) |
| 方案 | 子任务协作中,也要对dsFo(即F2)下subAlg判断是否处于actYes状态; |

| 23123 | 子任务流程未正常进入ActYes状态的问题1 |
| --- | --- |
| 示图 | ![](assets/489_子任务流程未正常进入ActYes状态的问题.png) |

| 23124 | 子任务流程未正常进入ActYes状态的问题2 |
| --- | --- |
| 示图 | ![](assets/490_子任务流程未正常进入ActYes状态的问题2.png) |
| 复现 | 防撞训练前两步,重启后,下飞即可复现; |

| 23125 | 来的及评价后的ActYes反省触发器不执行问题 `T` |
| --- | --- |
| 调试 | 发现,在静默成功的actYes流程控制中,取findIndex和deltaTime一直失败; |
| 分析 | 1. 取findIndex方法不对,应该根据ARSTime方式取下标才能取到; |
|  | 2. 应以rDemand.matchFo计算deltaTime,因为静默成功本来就是在等它; |
| 结果 | 改了`取findIndex方式`和`deltaTime计算方式`,后ok; |

| 23126 | 父子任务往复循环BUG |
| --- | --- |
| 示图 | ![](assets/491_父子任务往复循环BUG和同ds方案被反复尝试BUG.png) |
| 说明 | 如图中BUG1所示,父反思到子任务,子任务完成再递归到父,然后再子,再父; |
| 经测 | 子任务actYes后,继续父任务且失败了,再取下一ds方案,再子任务,形成循环; |
| 分析 | 1. 表面看是子任务消耗energy太多,导致很快耗尽 |
|  | 解决: energy消耗: `begin改为低消耗` & `行为输出高消耗`; |
| 分析 | 2. 预测有撞击风险时,父任务中也应该静默等待木棒出现; |
|  | 解决: 调试代码,看继续父任务时为什么会失败; |

| 23127 | 同ds方案被反复尝试BUG (见23126中示图) |
| --- | --- |
| 说明 | 如图示,首个红框F2已被解决为ActYes静默状态,但是后面还是一再的尝试; |

| 23128 | 多层嵌套子任务中ds重复问题 `T` |
| --- | --- |
| 示图 | ![](assets/492_多层嵌套子任务中ds重复问题.png) |
| 例子 | a. 主任务为吃饭,ds为过马路饭店吃; |
|  | b. 子任务为防止闯红灯被撞,ds为绿灯再过; |
|  | c. 子子任务为防止有车闯红灯撞来,ds为观察左右没车辆再继续过; |
|  | d. 子子子任务为防止有车闯红灯撞来,ds为观察左右没车辆再继续过; |
| 说明 | 如上图中F2重复 & 如上例中c和d的ds重复; |
| 分析 | 这问题未必是问题,就像打游戏,有怪就开枪,不断有怪不断开枪; |
| 结果 | 先解决23129问题,解决掉后,也许此问题不解也不影响什么; |
| 结果 | 其实就是dsFo重复的问题 `转至n23p14`; |

| 23129 | 父任务来的及评价和生成子任务之间逻辑调整 `T` |
| --- | --- |
| 说明 | 参考23128中例子,得出如下分析1和方案1; |
| 分析1 | 在c和d中,有一个截点,即来的及评价index,此后发生,可静默不生成子任务; |
|  | 即,先过马路,并在通过过程中观察左右,有车等等,没车继续过; |
| 方案1 | 把`父ds来的及评价A`,放在`反思生成子任务B`之前,如果A静默,则B不生成; |
| 结果1 | 方案1只是初步分析,不能给出清晰的修复指导,所以继续分析`转至23131`; |
| 结果 | 来的及评价在行为化中做,生成子任务不受其影响 `参考23132-方案1&问题3` |

<br><br><br>

## n23p13 父子任务防重
`CreateTime 2021.06.18`

在n23p12十测中,最终子任务有不断递归循环多层的BUG,本节将针对此BUG进行进一步分析,并且修复之;

| 23131 | 继续分析子任务嵌套太多问题-例2 `T` |
| --- | --- |
| 例子2 | 1. 预测:`X[有可能出现车撞过来]->{有危险}`; |
|  | 2. dsFo为:`A(做好准备)`,`B(真有车撞过来时)`,`C(闪躲到一旁)`; |
| 分析2 | 1. 其中B不能再用于反思预测危险,因为它是被动事件; |
|  | 2. 现在有重复A的BUG (即小鸟多次下飞,做防撞准备) (虽有效但太早); |
| 问题 | 现在的问题有两个:`1.B反思并生成了子任务;`,`2.A有可能多次发生;` |
|  | 问题1解决掉,问题2自然就不存在了; |
| 方案2 | B是ActYes,若它真发生,应该推进X,而不是反思子任务; |
|  | 1. 考虑将反思放到每一帧_Hav来执行,当前帧为B时回归X,非B时生成子任务; |
|  | 2. 或直接对当前的反思时序进行ARSTime评价,含静默Alg则不生成子任务; |
|  | 3. 说白了,就是在生成子任务前,先与父级Fo进行一轮ARSTime评价; |
|  | 4. 如果被父级静默,则不生成子任务; |
|  | 5. 如果未被父级静默,则生成子任务; |
| 结果 | 对当前问题套入新例子,进行再分析 `转23132`; |
| 结果 | 本例中,所示的`有车撞过来`,其实是父子任务防重,这个本来代码中就有支持; |

| 23132 | 继续分析子任务嵌套太多问题-例3 |
| --- | --- |
| 例3 | 延用,穿越森林可能遇虎,出门前带枪,如遇虎开枪吓跑它; |
| 示图 | ![](assets/493_子任务嵌套太多的问题.png) |
| 说明 | 如图,子任务反思没有中断条件,直接进行再反思,导致子任务层层累积; |
| 分析 | 其中子任务dsFo,反思为: |
|  | 1. 带枪违非法枪支携带法 (遇虎前) |
|  | 2. 出门可能遇老虎有危险 (遇虎时) |
|  | 3. 打虎违野生动物保护法 (遇虎后) |
| 方案1 | `遇虎前`和`遇虎后`都应生成子任务 `ds为:改为发声假枪 & 仅吓跑`; |
|  | > 经查代码,遇虎前后生成子任务ok; |
| 方案2 | `遇虎时`与父任务本来就是同一个任务,不应再生成为子任务; |
|  | > 经查代码,遇虎时与父任务去重也ok; |
| 问题3 | 是否判断ARSTime的cutIndex,以仅>cutIndex的做父子同任务防重? |
|  | A:在生成子任务后的行为化中,会判断ARSTime,此处不用; |

结果: 本节的父子防重,在代码上本来就是支持的,而n23p12中的重复并非父子未去重导致,所以本节废弃,转至n23p14;

<br><br><br>

## n23p14 dsFo的全树不应期
`CreateTime 2021.06.22`

在决策中,许多子任务中有重复的情况,而它们的解决方案其实是同样或者类似的,本节将针对此情况做支持,以使决策更高效;

| 23141 | TOM中的重复 `转至23142` |
| --- | --- |
| 示图 | ![](assets/494_TOM中重复示图.png) |
| 说明 | 如图示,在决策TOM树中,有许多重复的区块,我们应该考虑如何复用它们; |
| 结果 | 在updateSubDemand()的不应期代码已经支持,只是仅支持同层,而非全树; |

| 23142 | TOM重复的复用分析 `T` |
| --- | --- |
| 例1 | 用锤子钉十根钉子,只需准备一个锤子,分别钉入即可; |
|  | > Q:为什么只准备了一个锤子?为什么钉了十次? |
|  | > A:准备锤子被复用了,而钉的行为分别进行; |
| 例2 | 做十人量的饭; |
|  | > Q:为什么做了一锅饭?但即是十人量的?并且分别盛了十碗? |
|  | > A:做饭行为复用了,饭量直接调用了`十人量`这个固有值,盛饭没复用; |
| 例3 | 火神虫,可能烧我、咬我、让我饿，但我干掉它,这些就全解决了; |
|  | > A:dsFo[干掉它],可同时适用于这三个子任务; |
| 分析 | 1. 三个例子中可见,本质还是对于dsFo的复用 (用于不应期防生成同质任务); |
|  | 2. 以往已经有dsFo做不应期的任务防重机制了 (参考23102 & 23103); |
| 制定 | 任务生成与是否已发生或未来发生无关,所以这些子任务全会尝试生成; |
|  | 全树dsFo可适用任务全加入复用机制,如打死火神虫用于三个子任务; |
|  | 由不应期来实现复用更简单,即不需复用,而是直接不应期掉的子任务不生成; |
| 方案 | 对TOM全树的已actYes的dsFo进行复用; |
| 代码 | 旧代码已支持同层子任务下dsFo的不应期,本次迭代为支持全树; |

| 23143 | 扩展小问题 `T` |
| --- | --- |
| 问题 | 在钉钉子的例子中(参考23142),如何复用部分dsFo?有以下两种情况: |
|  | > 1.一个任务钉多个钉子; |
|  | > 2.每个钉子一个任务各跑各的(锤子在瞬时中自然会被重用); |
| 结果 | 综上,无需对`部分复用`专门写代码处理,它可兼容于现有决策机制来支持; |

<br><br><br>

## n23p15 十测3-子任务测试
`CreateTime 2021.06.25`

缩略词: `cutIndex=>已发生截点`,`actionIndex=>行为化进度截点`,`fromTIM=>瞬时记忆时序识别`;

| 23151 | dsFo经验太具象的问题 `T` |
| --- | --- |
| 示图 | ![](assets/495_重复多余的下飞动作.png) |
| 说明 | 如图,只是下飞,预测到危险,还没有真正看到射出的木棒,就连续的下飞四次; |
| 调试 | ![](assets/496_调试多余下飞准备动作的原因.png) |
| 说明 | 如图调试中,因为ds经验F123太过于具象 (有不必要的`下飞`准备动作); |
| 分析 | 因为具象,导致即使没看到射出的木棒,也会先做下飞这个不必要的准备动作; |
|  | 查dsFo的外类比抽象代码是否正常工作,为何经验太具象原因; |
| 调试 | ![](assets/497_查dsFo经验太具象的问题.png) |
|  | 说明: 如图示,更抽象的dsFo是存在的,只是被不应期掉了 `转至23152`; |

| 23152 | 抽象dsFo被不应期掉的原因 `因demand已发生截点有误,转至23153` |
| --- | --- |
| 说明 | F2,F3这些dsFo的A8应该静默等待才对,但却走了cHav代码,并最终失败; |
| 疑问 | 查为什么A8在ARS_Time评价中通过了,而不是走向静默等待ActYes; |
| 调试 | 经查,发现反思的已发生cutIndex定义不清晰,导致ARSTime评价失准; |
| 说明 | 1. fo.actionIndex没所谓,即使错了在行为化中也会自行更正; |
|  | 2. 但demand.cutIndex(已发生截点)必须正确,不然就会影响`来的及评价`; |
| 分析 | 应将反思时的lastMatchIndex匹配截点,与cutIndex已发生截点,分开表示; |
| 方案 | fromShortMem时,cutIndex = lastMatchIndex; |
|  | fromRT反思时,cutIndex需从父任务中做判断 (默认为-1) `转至23153`; |

| 23153 | 反思时TOM的cutIndex取值-方案制定 |
| --- | --- |
| 简介 | 本表主要针对反思的cutIndex取值源进行分析并撸码; |
| 方案1 | 从反思的baseFo的actionIndex取值 `5%`; |
|  | 分析: 仅actionIndex=-1时,才进行反思,所以此方案会全返-1; |
|  | 问题: 这么做会导致ARS_Time评价结果,全变成来的及,静默等待; |
|  | 例如: 即使父任务中已出现老虎,子任务还要等待老虎出现,显然是不理性的; |
|  | 解释: cutIndex本身就是ARS_Time判断的标杆,是不容错误的; |
|  | 解释: 不像actionIndex允许错,在ARS_Time评价后,再自行修正; |
| 方案2 | 逐级从父级R任务继承传递cutIndex `95%`; |
|  | 父级: 从dsFo.baseRDemand的cutIndex继承,来判断当前cutIndex; |
|  | 根级: 最终rootRDemand.cutIndex来自TIR_Fo.fromTIM的cutIndex; |
|  | 示图: ![](assets/498_TOM的cutIndex继承传递示图.png) |

| 23154 | 反思时TOM的cutIndex取值-代码规划 |
| --- | --- |
| 代码 | 从base的`0-cutIndex`,在cur中匹配lastIndex,作为当前的cutIndex; |

<br><br><br>
