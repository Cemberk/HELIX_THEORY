# 废弃HN & 分裂:理性反省和感性反省

> 注:
> 1. 在n24中，测了GL部分并发现它脱离场景的问题，从而对整个螺旋架构做了迭代，将过去两年的细节完善全部整合进螺旋架构。但最终的hSolution处，怕HN会再犯GL脱离场景的问题，本节直接废弃HN，并重新设计hSolution方法，然后回归测试训练。

***

<!-- TOC -->

- [废弃HN & 分裂:理性反省和感性反省](#废弃hn--分裂理性反省和感性反省)
  - [n25p01 螺旋架构-hSolution](#n25p01-螺旋架构-hsolution)
  - [n25p02 分裂理性反省和感性反省](#n25p02-分裂理性反省和感性反省)
  - [n25p03 反省分裂迭代-forecastIRT](#n25p03-反省分裂迭代-forecastirt)
  - [n25p04 回归测试-HRP下首条S问题](#n25p04-回归测试-hrp下首条s问题)
  - [n25p05 回归测试训练2](#n25p05-回归测试训练2)

<!-- /TOC -->

## n25p01 螺旋架构-hSolution
`CreateTime 2021.12.22`

H以往是用maskAlg联想的(参考n23p03),但它脱离场景,本文对hSolution进行迭代,使之能够取到更加契合当前场景的H解决方案;

| 25011 | hSolution迭代: `顺序原则`分析 |
| --- | --- |
| 简介 | 本表通过分析H联想的顺序,得出`顺序`线索; |
| 原则1 | ---->**本体在前,具象在后;** |
| 示例 | 找武器时没武器,先想到刀再想到厨房有刀,而无法直接武器想到厨房; |
| 反例 | 想吃香蕉时,去冰箱找食物,所以也有可能抽象在后,此顺序不明确; |
| 原则2 | ---->**当前场景在前,抽象场景在后,具象场景再后;** |
| 示例 | 在家时先想到厨房,但H失败后才会想到点外卖,在北京则先想到外卖; |
| 结果 | **综上,原则1不明确,原则2明确,对方案分析有重要意义;** |

| 25012 | hSolution迭代方案 |
| --- | --- |
| 方案1 | **--->补充mask,将当前场景所有已发生部分参与H联想;** |
| 途径1 | 将当前短时记忆树里任何cutIndex已发生的部分,做为mask用于H联想; |
| 途径2 | 将当前瞬时记忆序列,做为mask用于H联想; |
|  | 顺着抽到具象的优先级,逐个联想H解决方案 |
| 缺点1 | 毕竟脱离了场景 (因为这条联想路径,必然是先找到hAlg,再取hFo的); |
| 缺点2 | 因为脱离场景,导致取到大量不可行的H方案,浪费思维效率(尽想没用的); |
| 否掉 | 所以无法照顾到`原则2`,所以此方案pass `5%`; |
| 方案2 | **--->类似rSolution方式,写hSolution进行H联想;** |
| 分析 | 直接在场景内,找到mIsC的alg (分析模型图,评估可行性); |
| 优点 | 此方案不脱离场景,且支持`原则2-场景排序`,可以选用 `95%`; |
| 结果 | 选定方案2,实践参考25015; |

| 25013 | 是否废弃H节点 |
| --- | --- |
| 1不废弃 | HN内类比先不废弃,先这么写,等后面再考虑废弃之 (参考24171-3); |
|  | 虽然已经选择了方案2,但如果方案2实测不顺,可能还会用到HN,所以HN先留着; |
| 2废弃 | 选择了方案2,所以H节点可考虑废弃,`从普通时序中找元素,替代H`; |
|  | a. rSolution是阻止(N),而hSolution是推进(H); |
|  | b. 此处hSolution可参考rSolution的方式 (参考25012-方案2); |
| 3废弃 | 选择了方案2,所以H节点可考虑废弃,`从SP时序中找元素,替代H`; |

| 25014 | rSolution和hSolution对比 |
| --- | --- |
| R描述 | rSolution是从短时记忆树的RS取conPorts解决方案并做稳定性PK得出; |
| R特性 | rSolution偏感性`稳定性=SP的率`; |
| H描述 | hSolution是从当前场景下,取`自身+向抽象+向具象`,并分别在其SP中找H |
| H特性 | hSolution偏理性`经验性=SP的内容`; |

| 25015 | 代码规划 |
| --- | --- |
| 1 | 将HFo的末位,传到regroup(),进行识别反思 `暂不支持,随后需要再说`; |
|  | a. 目前已经支持在feedback反馈后,传到regroup `feedbackRegroup`; |
|  | b. 而取到hSolution后,行为化和反馈前,是否进行regroup反思 (需分析); |
| 2 | 尝试迭代rSolution (与N契合模型分析) `T`; |
|  | 分析: SP替代了N的作用,所以不必迭代之 `T`; |
| 3 | feedbackTIR和TOR两个理性反馈,构建的SP中找H经验 `T`; |
|  | 分析: 只有SP是在当前场景下的反馈 |
| 4 | 弃用H类型节点 (因为脱离场景,用SP替代) `参考25013-1,转至25025-3 T`; |
| 5 | hSolution的maskFos要收集:`自身+向抽象+向具象` `T`; |
| 6 | 在maskFos中根据SP评分竞争,找出最好的H解决方案 `T`; |
| 7 | TOOut.out()中isHNGL_toModel判断要改掉,因为H类型已弃用 `T`; |
| 8 | 核实原有SP对新hSolution的支持 `T` |

<br><br><br>

## n25p02 分裂理性反省和感性反省
`CreateTime 2021.12.24`

在上节中,rSolution和hSolution各需要感性和理性的SP经验`参考25014`,所以本节对反省算法做理性和感性分裂,使之能够分别支持二者;

| 25021 | 理性反省的路径 |
| --- | --- |
| I构建 | ①TCForecast预测输入时序，②feedbackTIR反馈，③IRT反省构建SP |
| O增强 | ④HDemand使用SP，⑤feedbackTOR反馈，⑥ORT反省增强SP |

| 25022 | 感性反省的路径 |
| --- | --- |
| I构建 | ①TCForecast预测输入P时序，②feedbackTIP反馈，③IRT反省构建SP |
| O增强 | ④P/RDemand使用SP，⑤feedbackTOP反馈，⑥ORT反省增强SP |
| 注③ | 现在此处是`正反向反馈外类比,并且是废弃状态`; |

| 25023 | 进一步分析: 可行性分析 & 问题分析 |
| --- | --- |
| 新使用 | hSolution如何用SP做评价竞争,如何执行; |
|  | 可以参考rSolution,场景相关fos以SP做稳定性评价,然后执行fo; |
| 新优点 | 感理性的分裂,有助于智能更理性 `参考25024-实例1`; |
|  | 解析: 理性和感性分别对应不同类型的反省和SP,使系统更精准智能; |
| 原问题 | 原HN有抽象,但没有稳定性(因为HN未开放反省),抽象的未必是稳定的; |
|  | 导致HN有可能遇到明明很指导,但就是不行的问题,此次废弃HN正好解决; |

| 25024 | 进一步分析: 实例分析 |
| --- | --- |
| 说明 | 为明确本节改动可行,本表找一些实例套入实例分析; |
| 实例1 | 理性不稳感性稳例: 过林未必遇虎,但遇虎时就必定危险`参考25023-优点` |

| 25025 | 代码规划 |
| --- | --- |
| 1 | TCForecast预测输入时序,在理性反省路径要处理PFos也要处理RFos `T`; |
| 2 | 正反向反馈外类比,改成感性IRT反省,构建感性SP `T`; |
| 3 | 废弃HN构建 (可先关掉,但不删代码,等hSolution跑定再删) `T`; |
| 4 | 感性和理性SP的表征,可以给SP节点增加spIndex来表示 `T`; |
| 5 | 写理性IRT算法 `T`; |
| 6 | 写感性IRT算法 `T`; |
| 7 | 写理性ORT算法 `T`; |
| 8 | 写感性ORT算法 `T`; |
| 9 | rSolution()算法迭代_针对SP反省分裂迭代的兼容 `T`; |

<br><br><br>

## n25p03 反省分裂迭代-forecastIRT
`CreateTime 2021.12.25`

反省分裂迭代,首先要对forecastIRT进行迭代(参考25025-1&2),本节对这部分深入分析与实践;

| 25031 | forecastIRT迭代分析 |
| --- | --- |
| 1 | pFos+rFos都参与反省 `T`; |
| 2 | 仅反省一步:非末位理性反省cutIndex后一帧,末位且有mv时则感性反省 `T` |
| 3 | 表征1: fo节点新增spDic<spIndex,spStrong> (末位key=fo长度) `T`; |
| 4 | 表征2: 将SP节点拆分成内容和强度值:内容保留于时序中,强度在spDic `T` |
| 5 | 表征3: spStrong表征S和P强度值 (这样SP节点也可废弃了) `T`; |
| 6 | 反省1: 这样也无需对SP再外类比了 (SP内容留在时序中,没的类比了) `T`; |
| 7 | 强度: SP增强单纯为线性,不存在再外类比的爆发式增涨 (更稳定,好事) `T`; |
| 8 | 反省2: IRT反省可直接重写,改动太大 `T`; |
| 9 | 决策: h解决方案在action()达到目标帧targetSPIndex时,调用hActYes`T` |
| 10 | 决策: 下标不急(弄巧成拙)评价,兼容支持输出类型(不能主动放出狮子) `T`; |
| 11 | 反馈: 整个rActYes针对rSolutionFo进行反省,而不是demand.fo `T`; |

| 25032 | 反省分裂迭代-在系统内整体运行流程 |
| --- | --- |
| 说明 | 本表步骤为现有步骤的基础上整理,有一部分要调整,大部分无需调整; |
| 1 | 在TCForecast中构建IRT触发器 `T`; |
| 2 | 在TIR和TIP两个feedback中反馈 `T`; |
| 3 | 触发IRT反省算法 `构建` (独立写TCRethink) `T`; |
| 4 | hSolution和rSolution使用SP (SP稳定性竞争) `T`; |
| 5 | actYes输出后,构建ORT反省触发器 `T`; |
| 6 | 在feedbackTOP和TOR中反馈 `T`; |
| 7 | 触发ORT反省算法 `增强` `T`; |

<br><br><br>

## n25p04 回归测试-HRP下首条S问题
`CreateTime 2021.12.27`

PRH三个任务在生成后,都直接转向了TCScore,而此时PRH下没有一条S,要从TCPlan下选出最优S,则肯定选不到,导致为空,本节解决这一部分;

| 25041 | 工作记忆树任务下_首条S的支持-问题分析 |
| --- | --- |
| 问题 | HRP三种Demand在任务生成后,都直接调用了TCScore,此时它们S为空; |
| 分析 | 此时执行score和plan,取最优路径末枝S(因为为空); |
| 说明 | 本表重要解决这一问题的继续决策问题; |
| 方案1 | 在scoreDic中把SRH都收集下,solution()只直接执行行为化; |
| 方案2 | 在scoreDic还是仅收集S,然后在solution()判断subDemands; |
| 方案3 | 在scoreDic还是仅收集S,后在plan中判断subDemand,solution只执行; |
| 分析1 | RH之间不存在评分竞争关系,所以不合适放到scoreDic和plan.best竞争; |
|  | 所以选择方案2,在solution中写死规则来实现即可 `废弃`; |
| 分析2 | Score评分,Plan路径,Solution解决,路径未必是竞争,RH优先级也是; |
|  | 所以选择方案3,plan对S取最优,同时对末尾RH做优先级规则 `转25041`; |

| 25042 | 工作记忆树任务下_首条S的支持-代码实践 |
| --- | --- |
| 1 | 在Plan竞争方法中对子subDemands判断和优先级来实现 `T`; |
| 2 | 其中subDemand: finish和without的不做处理 `T` |
| 3 | 其中subDemand: actYes状态则中止决策,继续等待; |
| 4 | 其它状态的,就以先R后H的优先级处理 (磨刀不误砍柴) `原本如此 T`; |
| 5 | 其它状态的,如是为空S,直接返回subDemand为末枝 (root也照样) `T`; |
| 6 | 每一级,都取最优S继续深入 `T`; |
| 7 | 每一级,只要感性淘汰,则不继续深入 `T`; |
| 8 | bestFo下所有subDemands都已完成或失败时,继续bestFo `T`; |

<br><br><br>

## n25p05 回归测试训练2
`CreateTime 2021.12.28`

| 25051 | BUG1_rSolution()下取rs的问题 |
| --- | --- |
| 说明 | 原本rs是从loopCache任务池取同抽具象路径上的R任务组; |
| 问题 | 但事实上现在loopCache只存root,rs方法算过期无用方法; |
| 结果 | 改为在rSolution中取:R任务生成时的pFos下同mv标识的替代RS `T`; |

| 24052 | 训练步骤规划 | 训练目标 |
| --- | --- | --- |
| 1 | 各危险地带,直击 x N | 被撞经验,危险地带概念 |
| 2 | 各安全地带,偏击 x N | 不被撞经验,安全地带概念 |
| 3 | 各危险地带飞(上/下)到安全地带 x N | 飞行经验,安全地带P经验 |
| 4 | 在危险地带直击 | 预测危险,并R任务决策飞躲 |

| 24053 | 时间紧急评否后的死循环问题 |
| --- | --- |
| 说明 | 时间紧急已评否,但还在不断对其进行决策,再评否,再决策,死循环; |
| 结果 | 在score_Single()中,对时间紧急评否的,评为理性淘汰 `T`; |

<br><br><br><br><br>
